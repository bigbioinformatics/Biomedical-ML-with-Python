{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ace58e3-d3d7-4743-a14c-21a4f6e2aa21",
   "metadata": {},
   "source": [
    "# Module 6 - Feature Selection - Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3c5bdf-2ad0-4cd2-89e5-c9b4a01b141b",
   "metadata": {},
   "source": [
    "For Homework I would like you to conduct your own feature selection proceedure on the PIMA native american dataset distributed with this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c0e58-1d2a-4bf7-892a-dbc2f216828f",
   "metadata": {},
   "source": [
    " ## About the PIMA dataset \n",
    "+ Number of Instances: 768\n",
    "+ Number of Attributes: 8 plus class \n",
    "+ For Each Attribute: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)\n",
    "\n",
    "+ Missing Attribute Values: Yes\n",
    "\n",
    "+ Class Distribution: (class value 1 is interpreted as \"tested positive for diabetes\")\n",
    "\n",
    "+ The datafile does not contain any column names you will have to generate them your self!\n",
    "\n",
    "This is a binary classification problem. To complete this homework you will need to load and tidy the data. Notice there are missing data that need to be addressed. Use the table 1 to help reveal any issues with the data distributions. The data is also not partitioned. You will have to conduct a 70:30 split before proceeding with feature selection.  I would like you to compare filter method, Boruta, and LASSO feature selection and validate your results in a final linear model using your reserved testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103cd06",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Let's get all the requirements sorted before we move on to the excercise. Most packages should be familiar at this point. Numpy, pandas, matplotlib, and seaborn where all introduced in Part I of the workshop in modules 1-3 and last week in module 5 we introduced tableone. Notice, today we will be using sklearn for the first time to do some machine learning. Don't worry too much about the models we'll be using or how to train them for now. This will the the topic for modules 7 & 8.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4fec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "!pip install --upgrade ipykernel\n",
    "#!pip install scipy\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install tableone\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install sklearn\n",
    "!pip install boruta\n",
    "\n",
    "# Globals\n",
    "seed = 1017\n",
    "\n",
    "#imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tableone import TableOne\n",
    "from boruta import BorutaPy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790bd5b1-61c0-435a-b1ae-3047d3519bae",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "Use table 1 to look at how the features are distributed grouped by the outcome. I have used the `<your code>` notation to indcate where you have to fill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bc3faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data as a pandas dataframe \n",
    "# Note, the datafile has no column names\n",
    "df = pd.read_csv(<your code>)\n",
    "\n",
    "# Generate table 1 - group by the outcome index\n",
    "TableOne(df, groupby=df.columns[<your code>],\n",
    "         pval=True,\n",
    "         dip_test=True,\n",
    "         normal_test=True,\n",
    "         tukey_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d5a51",
   "metadata": {},
   "source": [
    "Let's address the 2 warnings raised by the table 1 and see if we have to reformat some of the features.\n",
    "\n",
    "### Addressing the warnings\n",
    "Let's have a look at the disributions for those features that appeared in the warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae75a9a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot the feature distributions\n",
    "for feat in df.columns: \n",
    "    df[[feat]].dropna().plot.kde(bw_method='scott') #use bw_method=.02 for a lower bandwidth gaussian representation\n",
    "    plt.legend([feat])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9151012a",
   "metadata": {},
   "source": [
    "### Tasks:\n",
    "1. Impute missing values with the feature mean.\n",
    "2. Tuck in any features with long tails by log2 transform?\n",
    "3. Partition your data into 70% training and 30% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f634a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute any missing values with their column median\n",
    "df.fillna(<your code>, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log2 transform - you will need to identify any features with long tails\n",
    "df[cols] = np.log2(<your code>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bd82ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#70-30 partition\n",
    "df_test = <your code> #randomly sample 30% of observations\n",
    "df = <your code> #overwrite dataframe with testing samples removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb5a09a",
   "metadata": {},
   "source": [
    "## Comparing Models\n",
    "Let's define a function that will calculate the prodigious and parsimonious model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function that compares selected features to full model\n",
    "def compare_models(dataset, selfeat):\n",
    "    \"\"\"compare parsimonious and full linear model\"\"\"\n",
    "    \n",
    "    # get predictors and labels\n",
    "    X = dataset.drop(<your code>,axis=1)  #independent columns\n",
    "    y = dataset[<your code>]    #outcome\n",
    "\n",
    "    #get selected feature indecies\n",
    "    isel = [X.columns.get_loc(feat) for feat in selfeat if feat in X]\n",
    "    \n",
    "    #70-30 split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=seed)\n",
    " \n",
    "\n",
    "    #define the prodigious and parsimonious logistic models\n",
    "    prodmodel = linear_model.LinearRegression()\n",
    "    parsmodel = linear_model.LinearRegression()\n",
    "\n",
    "    #Fit the models\n",
    "    prodmodel.fit(X_train, y_train)\n",
    "    parsmodel.fit(X_train[selfeat], y_train) \n",
    "\n",
    "    #Report errors\n",
    "    display('Prodigious Model Score: %.2f' %prodmodel.score(X_test, y_test))\n",
    "    display('Parsimonious Model Score: %.2f' %parsmodel.score(X_test[selfeat], y_test))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d92207",
   "metadata": {},
   "source": [
    "## Filter Method\n",
    "The Table 1 conveniently has calculated the association of each feature with the outcome. Let's select only those features that are significatly (p<.05) associated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21e6e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selfeat = [<your code>]\n",
    "compare_models(df, selfeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3da975",
   "metadata": {},
   "source": [
    "## Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f711f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictors and labels\n",
    "X = np.array(df.drop(<your code>, axis=1)) \n",
    "y = np.array(df[<your code>])\n",
    "\n",
    "# define random forest classifier for boruta\n",
    "forest = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "forest.fit(X, y)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(forest, n_estimators='auto', verbose=0, random_state=seed)\n",
    "\n",
    "# find all relevant features\n",
    "feat_selector.fit(X, y)\n",
    "\n",
    "# zip my names, ranks, and decisions in a single iterable\n",
    "feature_ranks = list(zip(df.columns.drop(<your code>), \n",
    "                         feat_selector.ranking_, \n",
    "                         feat_selector.support_))\n",
    "\n",
    "# iterate through and print out the results\n",
    "for feat in feature_ranks:\n",
    "    display('Feature: {:<25} Rank: {},  Keep: {}'.format(feat[0], feat[1], feat[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3269faa",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# get predictors and labels\n",
    "X = np.array(df.drop(<your code>, axis=1)) \n",
    "y = np.array(df[<your code>])\n",
    "\n",
    "#train lasso model with 5-fold cross validataion\n",
    "lasso = LassoCV(cv=5, random_state=0).fit(X, y)\n",
    "\n",
    "#display the model score\n",
    "lasso.score(X, y)\n",
    "\n",
    "#plot feature importance based on coeficients\n",
    "importance = np.abs(lasso.coef_)\n",
    "feature_names = np.array(df.columns.drop(<your code>))\n",
    "plt.bar(height=importance, x=feature_names)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature importances via coefficients\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d990aa",
   "metadata": {},
   "source": [
    "## Report\n",
    "Create a final logistic regression model with your selected features and compute the accuracy to predict outcomes in the reserved testing set.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5159c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a logistic regression model and report accuracy\n",
    "<your code>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
